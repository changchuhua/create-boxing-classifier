{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "- [Imports](#imports)\n",
    "- [Visual Test](#vid)\n",
    "- [Quantitative Test](#quantitative)\n",
    "    - [Classification on Test Keypoints](#keypointclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Imports<a id=imports></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\chang\\.conda\\envs\\opencv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\chang\\.conda\\envs\\opencv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\chang\\.conda\\envs\\opencv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\chang\\.conda\\envs\\opencv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\chang\\.conda\\envs\\opencv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\chang\\.conda\\envs\\opencv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\chang\\.conda\\envs\\opencv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\chang\\.conda\\envs\\opencv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\chang\\.conda\\envs\\opencv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\chang\\.conda\\envs\\opencv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\chang\\.conda\\envs\\opencv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\chang\\.conda\\envs\\opencv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0801 07:31:45.997728 19292 deprecation_wrapper.py:119] From D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\tf_pose\\mobilenet\\mobilenet.py:369: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from inspect import signature\n",
    "from itertools import cycle\n",
    "from IPython.display import HTML\n",
    "from IPython.display import Image\n",
    "import pickle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import recall_score, make_scorer, roc_curve, classification_report, precision_recall_curve, roc_auc_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this to prevent GPU process issues\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Visual Test<a id=vid></a>\n",
    "Let us import the necessary code for our video tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('TfPoseEstimator-Video')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('[%(asctime)s] [%(name)s] [%(levelname)s] %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "fps_time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--showBG'], dest='showBG', nargs=None, const=None, default=True, type=<class 'bool'>, choices=None, help='False to show skeleton only.', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='tf-pose-estimation Video')\n",
    "parser.add_argument('--video', type=str, default='')\n",
    "parser.add_argument('--resolution', type=str, default='432x368', help='network input resolution. default=432x368')\n",
    "parser.add_argument('--model', type=str, default='mobilenet_thin', help='cmu / mobilenet_thin / mobilenet_v2_large / mobilenet_v2_small')\n",
    "parser.add_argument('--show-process', type=bool, default=False,\n",
    "                    help='for debug purpose, if enabled, speed for inference is dropped.')\n",
    "parser.add_argument('--showBG', type=bool, default=True, help='False to show skeleton only.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our testing function has to be slightly altered to account for the engineered features that we have to create on the fly.<br/>\n",
    "The rest of the function stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def vidtest(args):\n",
    "    \n",
    "    fps_time = 0\n",
    "    \n",
    "    lis=[]\n",
    "    for x in range(1,18):\n",
    "        lis.append('x'+str(x))\n",
    "        lis.append('y'+str(x))\n",
    "    header=pd.DataFrame(columns=lis)\n",
    "    \n",
    "    xparts=['x1','x2','x3','x4','x5','x6','x7','x8','x11']\n",
    "    yparts=['y1','y2','y3','y4','y5','y6','y7','y8','y11']\n",
    "    drop=['x0', 'x10', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x9', 'y0', 'y10', 'y12', 'y13', 'y14', 'y15', 'y16', 'y17', 'y9']\n",
    "    \n",
    "    logger.debug('initialization %s : %s' % (args.model, get_graph_path(args.model)))\n",
    "    w, h = model_wh(args.resolution)\n",
    "    e = TfPoseEstimator(get_graph_path(args.model), target_size=(w, h))\n",
    "    cap = cv2.VideoCapture(args.video)\n",
    "\n",
    "    if cap.isOpened() is False:\n",
    "        print(\"Error opening video stream or file\")\n",
    "    while cap.isOpened():\n",
    "        try:\n",
    "            ret_val, image = cap.read()\n",
    "            humans = e.inference(image, upsample_size=4.0)\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "        if not args.showBG:\n",
    "            image = np.zeros(image.shape)\n",
    "        image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "\n",
    "        cv2.putText(image, \"FPS: %f\" % (1.0 / (time.time() - fps_time)), (10, 10),  cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        move='none'\n",
    "\n",
    "        try:\n",
    "            part=re.findall('BodyPart:(.*?)-',str(humans[0]))\n",
    "            xco=re.findall('\\((.*?),',str(humans[0]))\n",
    "            yco=re.findall(', (.*?)\\)',str(humans[0]))\n",
    "            xpart=['x'+c for c in part]\n",
    "            ypart=['y'+c for c in part]\n",
    "            test1=pd.DataFrame([[float(x) for x in xco+yco]],columns=xpart+ypart)\n",
    "            data=pd.concat([header,test1],sort=True)\n",
    "\n",
    "            data.drop(columns=drop,inplace=True) #create our new features based on our previous feature engineering\n",
    "            data[xparts]=data[xparts].subtract(data['x1'],axis=0)\n",
    "            data[yparts]=data[yparts].subtract(data['y1'],axis=0)\n",
    "            data.fillna(0,inplace=True)\n",
    "    \n",
    "            data['shwidth']=np.hypot((data.x2-data.x5),(data.y2-data.y5))\n",
    "            data['splength']=np.hypot((data.x1-((data.x8+data.x11)/2)),(data.y1-((data.y8+data.y11)/2)))\n",
    "            data['lhnsh']=np.hypot((data.x7-data.x5),(data.y7-data.y5))*data.shwidth/data.splength\n",
    "            data['rhnsh']=np.hypot((data.x4-data.x2),(data.y4-data.y2))*data.shwidth/data.splength\n",
    "            data['lelsh']=np.hypot((data.x6-data.x5),(data.y6-data.y5))*data.shwidth/data.splength\n",
    "            data['relsh']=np.hypot((data.x3-data.x2),(data.y3-data.y2))*data.shwidth/data.splength #end of feature creation\n",
    "            \n",
    "            predict=mod.predict(data.to_numpy())\n",
    "            if predict[0]==0:\n",
    "                move='none'\n",
    "            elif predict[0]==1:\n",
    "                move='guard'\n",
    "            elif predict[0]==2:\n",
    "                move='jab'\n",
    "            elif predict[0]==3:\n",
    "                move='cross'\n",
    "            elif predict[0]==4:\n",
    "                move='hook'\n",
    "            elif predict[0]==5:\n",
    "                move='uppercut'\n",
    "            else:\n",
    "                move='none'\n",
    "\n",
    "        except:\n",
    "            move='not detected'\n",
    "\n",
    "        finally:\n",
    "            cv2.putText(image,\n",
    "                        'move: '+move,\n",
    "                        (10, 30),  cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                        (0, 0, 255), 2)\n",
    "            out.write(image)\n",
    "            cv2.imshow('tf-pose-estimation result', image)\n",
    "            fps_time = time.time()\n",
    "\n",
    "            if cv2.waitKey(1) == 27:\n",
    "                break\n",
    "            \n",
    "    cv2.destroyAllWindows()\n",
    "    logger.debug('finished+')\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we set our output video codec to 'mp4v'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we perform our estimation, prediction and output with the loop below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-08-01 01:19:57,218] [TfPoseEstimator-Video] [DEBUG] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "[2019-08-01 01:19:57,218] [TfPoseEstimator-Video] [DEBUG] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "I0801 01:19:57.218427 16048 <ipython-input-8-5cee673a3860>:15] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "[2019-08-01 01:19:57,222] [TfPoseEstimator] [INFO] loading graph from D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb(default size=432x368)\n",
      "I0801 01:19:57.222390 16048 estimator.py:309] loading graph from D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb(default size=432x368)\n",
      "[2019-08-01 01:27:47,421] [TfPoseEstimator-Video] [DEBUG] finished+\n",
      "[2019-08-01 01:27:47,421] [TfPoseEstimator-Video] [DEBUG] finished+\n",
      "I0801 01:27:47.421624 16048 <ipython-input-8-5cee673a3860>:90] finished+\n",
      "[2019-08-01 01:27:47,630] [TfPoseEstimator-Video] [DEBUG] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "[2019-08-01 01:27:47,630] [TfPoseEstimator-Video] [DEBUG] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "I0801 01:27:47.630074 16048 <ipython-input-8-5cee673a3860>:15] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "[2019-08-01 01:27:47,633] [TfPoseEstimator] [INFO] loading graph from D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb(default size=432x368)\n",
      "I0801 01:27:47.633058 16048 estimator.py:309] loading graph from D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb(default size=432x368)\n",
      "[2019-08-01 01:35:23,953] [TfPoseEstimator-Video] [DEBUG] finished+\n",
      "[2019-08-01 01:35:23,953] [TfPoseEstimator-Video] [DEBUG] finished+\n",
      "I0801 01:35:23.953237 16048 <ipython-input-8-5cee673a3860>:90] finished+\n",
      "[2019-08-01 01:35:24,346] [TfPoseEstimator-Video] [DEBUG] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "[2019-08-01 01:35:24,346] [TfPoseEstimator-Video] [DEBUG] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "I0801 01:35:24.346188 16048 <ipython-input-8-5cee673a3860>:15] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "[2019-08-01 01:35:24,348] [TfPoseEstimator] [INFO] loading graph from D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb(default size=432x368)\n",
      "I0801 01:35:24.348182 16048 estimator.py:309] loading graph from D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb(default size=432x368)\n",
      "[2019-08-01 01:42:51,746] [TfPoseEstimator-Video] [DEBUG] finished+\n",
      "[2019-08-01 01:42:51,746] [TfPoseEstimator-Video] [DEBUG] finished+\n",
      "I0801 01:42:51.746526 16048 <ipython-input-8-5cee673a3860>:90] finished+\n",
      "[2019-08-01 01:42:52,217] [TfPoseEstimator-Video] [DEBUG] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "[2019-08-01 01:42:52,217] [TfPoseEstimator-Video] [DEBUG] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "I0801 01:42:52.217781 16048 <ipython-input-8-5cee673a3860>:15] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "[2019-08-01 01:42:52,221] [TfPoseEstimator] [INFO] loading graph from D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb(default size=432x368)\n",
      "I0801 01:42:52.221771 16048 estimator.py:309] loading graph from D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb(default size=432x368)\n",
      "[2019-08-01 01:50:46,202] [TfPoseEstimator-Video] [DEBUG] finished+\n",
      "[2019-08-01 01:50:46,202] [TfPoseEstimator-Video] [DEBUG] finished+\n",
      "I0801 01:50:46.202834 16048 <ipython-input-8-5cee673a3860>:90] finished+\n",
      "[2019-08-01 01:50:46,821] [TfPoseEstimator-Video] [DEBUG] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "[2019-08-01 01:50:46,821] [TfPoseEstimator-Video] [DEBUG] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "I0801 01:50:46.821199 16048 <ipython-input-8-5cee673a3860>:15] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "[2019-08-01 01:50:46,825] [TfPoseEstimator] [INFO] loading graph from D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb(default size=432x368)\n",
      "I0801 01:50:46.825168 16048 estimator.py:309] loading graph from D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb(default size=432x368)\n",
      "[2019-08-01 02:00:42,546] [TfPoseEstimator-Video] [DEBUG] finished+\n",
      "[2019-08-01 02:00:42,546] [TfPoseEstimator-Video] [DEBUG] finished+\n",
      "I0801 02:00:42.546746 16048 <ipython-input-8-5cee673a3860>:90] finished+\n",
      "[2019-08-01 02:00:42,910] [TfPoseEstimator-Video] [DEBUG] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "[2019-08-01 02:00:42,910] [TfPoseEstimator-Video] [DEBUG] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "I0801 02:00:42.910771 16048 <ipython-input-8-5cee673a3860>:15] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "[2019-08-01 02:00:42,913] [TfPoseEstimator] [INFO] loading graph from D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb(default size=432x368)\n",
      "I0801 02:00:42.913763 16048 estimator.py:309] loading graph from D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb(default size=432x368)\n",
      "[2019-08-01 02:11:17,766] [TfPoseEstimator-Video] [DEBUG] finished+\n",
      "[2019-08-01 02:11:17,766] [TfPoseEstimator-Video] [DEBUG] finished+\n",
      "I0801 02:11:17.766688 16048 <ipython-input-8-5cee673a3860>:90] finished+\n",
      "[2019-08-01 02:11:18,566] [TfPoseEstimator-Video] [DEBUG] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "[2019-08-01 02:11:18,566] [TfPoseEstimator-Video] [DEBUG] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "I0801 02:11:18.566549 16048 <ipython-input-8-5cee673a3860>:15] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "[2019-08-01 02:11:18,570] [TfPoseEstimator] [INFO] loading graph from D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb(default size=432x368)\n",
      "I0801 02:11:18.570539 16048 estimator.py:309] loading graph from D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb(default size=432x368)\n",
      "[2019-08-01 02:23:59,997] [TfPoseEstimator-Video] [DEBUG] finished+\n",
      "[2019-08-01 02:23:59,997] [TfPoseEstimator-Video] [DEBUG] finished+\n",
      "I0801 02:23:59.997405 16048 <ipython-input-8-5cee673a3860>:90] finished+\n",
      "[2019-08-01 02:24:00,917] [TfPoseEstimator-Video] [DEBUG] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "[2019-08-01 02:24:00,917] [TfPoseEstimator-Video] [DEBUG] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "I0801 02:24:00.917944 16048 <ipython-input-8-5cee673a3860>:15] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "[2019-08-01 02:24:00,923] [TfPoseEstimator] [INFO] loading graph from D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb(default size=432x368)\n",
      "I0801 02:24:00.923930 16048 estimator.py:309] loading graph from D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb(default size=432x368)\n",
      "[2019-08-01 02:37:50,499] [TfPoseEstimator-Video] [DEBUG] finished+\n",
      "[2019-08-01 02:37:50,499] [TfPoseEstimator-Video] [DEBUG] finished+\n",
      "I0801 02:37:50.499877 16048 <ipython-input-8-5cee673a3860>:90] finished+\n",
      "[2019-08-01 02:37:51,554] [TfPoseEstimator-Video] [DEBUG] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "[2019-08-01 02:37:51,554] [TfPoseEstimator-Video] [DEBUG] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "I0801 02:37:51.554058 16048 <ipython-input-8-5cee673a3860>:15] initialization cmu : D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb\n",
      "[2019-08-01 02:37:51,557] [TfPoseEstimator] [INFO] loading graph from D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb(default size=432x368)\n",
      "I0801 02:37:51.557049 16048 estimator.py:309] loading graph from D:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\models\\graph/cmu/graph_opt.pb(default size=432x368)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-ddedb3bfc975>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwritepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfourcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m29.72\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1280\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m720\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'./data/model2/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0me_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mvidtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-5cee673a3860>\u001b[0m in \u001b[0;36mvidtest\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'initialization %s : %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_graph_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_wh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolution\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfPoseEstimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_graph_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Insync\\Team Drive\\amilame@gmail.com\\amilame@gmail.com\\HAR\\tf-pose-estimation\\tf_pose\\estimator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph_path, target_size, tf_config)\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;31m# warm-up\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         self.persistent_sess.run(tf.variables_initializer(\n\u001b[1;32m--> 343\u001b[1;33m             [v for v in tf.global_variables() if\n\u001b[0m\u001b[0;32m    344\u001b[0m              v.name.split(':')[0] in [x.decode('utf-8') for x in\n\u001b[0;32m    345\u001b[0m                                       self.persistent_sess.run(tf.report_uninitialized_variables())]\n",
      "\u001b[1;32m~\\.conda\\envs\\opencv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\opencv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\opencv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\opencv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1354\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\opencv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\opencv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path='./data/model2/'\n",
    "args=parser.parse_args((\"--video=../results/test.mp4 --model=cmu\").split())\n",
    "for e_name in os.listdir(path):\n",
    "    model=os.path.splitext(e_name)[0]\n",
    "    writepath=\"../results/test2/\"+str(model)+\".mp4\"\n",
    "    out=cv2.VideoWriter(writepath, fourcc, 30, (1280,720))\n",
    "    mod=pickle.load(open(r'./data/model2/'+e_name, 'rb'))\n",
    "    vidtest(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of ADA:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video width=\"1500\" height=\"1000\" controls><source src=\"../results/test2/ADA.mp4\" type=\"video/mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of bagging classifier:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video width=\"1500\" height=\"1000\" controls><source src=\"../results/test2/bagging classifier.mp4\" type=\"video/mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of DecisionTree:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video width=\"1500\" height=\"1000\" controls><source src=\"../results/test2/DecisionTree.mp4\" type=\"video/mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of ef:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video width=\"1500\" height=\"1000\" controls><source src=\"../results/test2/ef.mp4\" type=\"video/mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of GBoost:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video width=\"1500\" height=\"1000\" controls><source src=\"../results/test2/GBoost.mp4\" type=\"video/mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of knn:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video width=\"1500\" height=\"1000\" controls><source src=\"../results/test2/knn.mp4\" type=\"video/mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of lr with reg:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video width=\"1500\" height=\"1000\" controls><source src=\"../results/test2/lr with reg.mp4\" type=\"video/mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of random forest:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video width=\"1500\" height=\"1000\" controls><source src=\"../results/test2/random forest.mp4\" type=\"video/mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of SVC:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video width=\"1500\" height=\"1000\" controls><source src=\"../results/test2/SVC.mp4\" type=\"video/mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of XGB:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video width=\"1500\" height=\"1000\" controls><source src=\"../results/test2/XGB.mp4\" type=\"video/mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def showvideo(i):\n",
    "    display(HTML(\"\"\"<video width=\"1500\" height=\"1000\" controls><source src=\"{}\" type=\"video/mp4\"></video>\"\"\".format(i)))\n",
    "\n",
    "path='./data/model2/'\n",
    "for e_name in os.listdir(path):\n",
    "    model=os.path.splitext(e_name)[0]\n",
    "    print('result of '+str(model)+':')\n",
    "    showvideo('../results/test2/'+str(model)+'.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through visual inspection, we get much better results with our newly trained models.<br/>\n",
    "Taking Gradient Boosting and SVC videos as an example, the predictions are much more stable and less jumpy as compared to our first round of testing.<br/>\n",
    "The predictors are also much better at predicting the sequence of jab, cross, hook and uppercut movements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Quantitative Test<a id=quantitative></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification on Test Keypoints<a id=keypointclass></a>\n",
    "We utilize the same keypoint data extract in our first round of testing.<br/>\n",
    "We display the classification reports and observe the accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "none=pd.read_csv('../results/test/none.csv')\n",
    "guard=pd.read_csv('../results/test/guard.csv')\n",
    "jab=pd.read_csv('../results/test/jab.csv')\n",
    "cross=pd.read_csv('../results/test/cross.csv')\n",
    "hook=pd.read_csv('../results/test/hook.csv')\n",
    "upcut=pd.read_csv('../results/test/uppercut.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "none['move']=0\n",
    "guard['move']=1\n",
    "jab['move']=2\n",
    "cross['move']=3\n",
    "hook['move']=4\n",
    "upcut['move']=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>move</th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>x16</th>\n",
       "      <th>...</th>\n",
       "      <th>y16</th>\n",
       "      <th>y17</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.69</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   move    x0    x1  x10   x11   x12  x13   x14  x15   x16  ...   y16  y17  \\\n",
       "0     0  0.75  0.69  NaN  0.63  0.67  NaN  0.75  NaN  0.71  ...  0.12  NaN   \n",
       "1     0  0.75  0.68  NaN  0.62  0.63  NaN  0.75  NaN  0.71  ...  0.13  NaN   \n",
       "2     0  0.74  0.68  NaN  0.63  0.66  NaN  0.74  NaN  0.70  ...  0.13  NaN   \n",
       "3     0  0.74  0.67  NaN  0.62  0.64  NaN  0.74  NaN  0.70  ...  0.14  NaN   \n",
       "4     0  0.73  0.67  NaN  0.63   NaN  NaN  0.73  NaN  0.69  ...  0.14  NaN   \n",
       "\n",
       "     y2    y3    y4    y5  y6  y7    y8    y9  \n",
       "0  0.26  0.54  0.79  0.27 NaN NaN  0.68  0.90  \n",
       "1  0.26  0.53  0.79  0.27 NaN NaN  0.67  0.88  \n",
       "2  0.26  0.52  0.79  0.27 NaN NaN  0.67  0.89  \n",
       "3  0.26  0.52  0.78  0.27 NaN NaN  0.69  0.91  \n",
       "4  0.27  0.52  0.78  0.27 NaN NaN  0.69  0.91  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.concat([none,guard,jab,cross,hook,upcut],sort=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this run of testing, we have to create the features we created in our feature engineering section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xparts=['x1','x2','x3','x4','x5','x6','x7','x8','x11']\n",
    "yparts=['y1','y2','y3','y4','y5','y6','y7','y8','y11']\n",
    "drop=['x0', 'x10', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x9', 'y0', 'y10', 'y12', 'y13', 'y14', 'y15', 'y16', 'y17', 'y9']\n",
    "data.drop(columns=drop,inplace=True)\n",
    "\n",
    "data[xparts]=data[xparts].subtract(data['x1'],axis=0)\n",
    "data[yparts]=data[yparts].subtract(data['y1'],axis=0)\n",
    "data.fillna(0,inplace=True)\n",
    "\n",
    "data['shwidth']=np.hypot((data.x2-data.x5),(data.y2-data.y5))\n",
    "data['splength']=np.hypot((data.x1-((data.x8+data.x11)/2)),(data.y1-((data.y8+data.y11)/2)))\n",
    "data['lhnsh']=np.hypot((data.x7-data.x5),(data.y7-data.y5))*data.shwidth/data.splength\n",
    "data['rhnsh']=np.hypot((data.x4-data.x2),(data.y4-data.y2))*data.shwidth/data.splength\n",
    "data['lelsh']=np.hypot((data.x6-data.x5),(data.y6-data.y5))*data.shwidth/data.splength\n",
    "data['relsh']=np.hypot((data.x3-data.x2),(data.y3-data.y2))*data.shwidth/data.splength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>move</th>\n",
       "      <th>x1</th>\n",
       "      <th>x11</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>...</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>shwidth</th>\n",
       "      <th>splength</th>\n",
       "      <th>lhnsh</th>\n",
       "      <th>rhnsh</th>\n",
       "      <th>lelsh</th>\n",
       "      <th>relsh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.050990</td>\n",
       "      <td>0.420476</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>0.066796</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>0.034726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.041231</td>\n",
       "      <td>0.405494</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.056008</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.027921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.041231</td>\n",
       "      <td>0.405771</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>0.055701</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>0.026903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.041231</td>\n",
       "      <td>0.415482</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.053191</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.026105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.415271</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.050466</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.024253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   move   x1   x11    x2    x3    x4    x5   x6   x7    x8  ...    y5   y6  \\\n",
       "0     0  0.0 -0.06  0.02  0.08  0.17 -0.03  0.0  0.0  0.02  ...  0.01  0.0   \n",
       "1     0  0.0 -0.06  0.02  0.07  0.17 -0.02  0.0  0.0  0.02  ...  0.01  0.0   \n",
       "2     0  0.0 -0.05  0.02  0.07  0.16 -0.02  0.0  0.0  0.00  ...  0.01  0.0   \n",
       "3     0  0.0 -0.05  0.02  0.06  0.15 -0.02  0.0  0.0  0.01  ...  0.00  0.0   \n",
       "4     0  0.0 -0.04  0.02  0.05  0.14 -0.02  0.0  0.0  0.01  ...  0.00  0.0   \n",
       "\n",
       "    y7    y8   shwidth  splength     lhnsh     rhnsh     lelsh     relsh  \n",
       "0  0.0  0.42  0.050990  0.420476  0.003835  0.066796  0.003835  0.034726  \n",
       "1  0.0  0.41  0.041231  0.405494  0.002274  0.056008  0.002274  0.027921  \n",
       "2  0.0  0.41  0.041231  0.405771  0.002272  0.055701  0.002272  0.026903  \n",
       "3  0.0  0.42  0.041231  0.415482  0.001985  0.053191  0.001985  0.026105  \n",
       "4  0.0  0.42  0.040000  0.415271  0.001926  0.050466  0.001926  0.024253  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seem to be no issues with our dataset. Let us proceed with the testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X=data[[x for x in data.columns if x != 'move']].to_numpy()\n",
    "y=data['move']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our test results are given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for  ADA :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67       926\n",
      "           1       0.97      0.34      0.50      2271\n",
      "           2       0.05      0.14      0.07       281\n",
      "           3       0.69      0.30      0.42       195\n",
      "           4       0.18      0.36      0.24       172\n",
      "           5       0.13      0.99      0.22       155\n",
      "\n",
      "    accuracy                           0.42      4000\n",
      "   macro avg       0.45      0.46      0.35      4000\n",
      "weighted avg       0.76      0.42      0.48      4000\n",
      "\n",
      "Results for  bagging classifier :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.68      0.68       926\n",
      "           1       0.99      0.35      0.51      2271\n",
      "           2       0.75      0.34      0.47       281\n",
      "           3       0.09      0.63      0.16       195\n",
      "           4       0.33      0.60      0.42       172\n",
      "           5       0.30      0.90      0.45       155\n",
      "\n",
      "    accuracy                           0.47      4000\n",
      "   macro avg       0.52      0.58      0.45      4000\n",
      "weighted avg       0.80      0.47      0.52      4000\n",
      "\n",
      "Results for  DecisionTree :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.66      0.64       926\n",
      "           1       0.97      0.36      0.53      2271\n",
      "           2       0.67      0.32      0.43       281\n",
      "           3       0.07      0.45      0.12       195\n",
      "           4       0.23      0.62      0.34       172\n",
      "           5       0.33      0.77      0.46       155\n",
      "\n",
      "    accuracy                           0.46      4000\n",
      "   macro avg       0.48      0.53      0.42      4000\n",
      "weighted avg       0.77      0.46      0.52      4000\n",
      "\n",
      "Results for  ef :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.69      0.77       926\n",
      "           1       0.98      0.45      0.62      2271\n",
      "           2       0.81      0.40      0.53       281\n",
      "           3       0.12      0.90      0.22       195\n",
      "           4       0.34      0.80      0.47       172\n",
      "           5       0.59      0.99      0.74       155\n",
      "\n",
      "    accuracy                           0.56      4000\n",
      "   macro avg       0.62      0.70      0.56      4000\n",
      "weighted avg       0.86      0.56      0.63      4000\n",
      "\n",
      "Results for  GBoost :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.68      0.72       926\n",
      "           1       0.99      0.35      0.52      2271\n",
      "           2       0.69      0.42      0.52       281\n",
      "           3       0.12      0.90      0.22       195\n",
      "           4       0.29      0.66      0.40       172\n",
      "           5       0.40      0.97      0.57       155\n",
      "\n",
      "    accuracy                           0.50      4000\n",
      "   macro avg       0.54      0.66      0.49      4000\n",
      "weighted avg       0.82      0.50      0.55      4000\n",
      "\n",
      "Results for  knn :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.72      0.80       926\n",
      "           1       0.98      0.53      0.69      2271\n",
      "           2       0.68      0.68      0.68       281\n",
      "           3       0.14      0.85      0.24       195\n",
      "           4       0.52      0.77      0.62       172\n",
      "           5       0.46      0.95      0.62       155\n",
      "\n",
      "    accuracy                           0.63      4000\n",
      "   macro avg       0.61      0.75      0.61      4000\n",
      "weighted avg       0.86      0.63      0.69      4000\n",
      "\n",
      "Results for  lr with reg :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.66      0.74       926\n",
      "           1       0.99      0.85      0.91      2271\n",
      "           2       0.78      0.58      0.67       281\n",
      "           3       0.21      0.71      0.32       195\n",
      "           4       0.54      0.34      0.41       172\n",
      "           5       0.44      0.94      0.59       155\n",
      "\n",
      "    accuracy                           0.76      4000\n",
      "   macro avg       0.63      0.68      0.61      4000\n",
      "weighted avg       0.86      0.76      0.79      4000\n",
      "\n",
      "Results for  random forest :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.69      0.74       926\n",
      "           1       0.98      0.40      0.57      2271\n",
      "           2       0.77      0.34      0.47       281\n",
      "           3       0.11      0.89      0.20       195\n",
      "           4       0.34      0.62      0.44       172\n",
      "           5       0.49      0.99      0.66       155\n",
      "\n",
      "    accuracy                           0.52      4000\n",
      "   macro avg       0.58      0.66      0.51      4000\n",
      "weighted avg       0.83      0.52      0.58      4000\n",
      "\n",
      "Results for  SVC :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.65      0.74       926\n",
      "           1       0.98      0.91      0.94      2271\n",
      "           2       0.69      0.50      0.58       281\n",
      "           3       0.26      0.73      0.39       195\n",
      "           4       0.64      0.41      0.50       172\n",
      "           5       0.40      0.83      0.54       155\n",
      "\n",
      "    accuracy                           0.79      4000\n",
      "   macro avg       0.64      0.67      0.61      4000\n",
      "weighted avg       0.86      0.79      0.81      4000\n",
      "\n",
      "Results for  XGB :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.68      0.72       926\n",
      "           1       0.99      0.33      0.50      2271\n",
      "           2       0.75      0.41      0.53       281\n",
      "           3       0.11      0.91      0.20       195\n",
      "           4       0.41      0.74      0.53       172\n",
      "           5       0.45      0.99      0.62       155\n",
      "\n",
      "    accuracy                           0.49      4000\n",
      "   macro avg       0.58      0.68      0.52      4000\n",
      "weighted avg       0.84      0.49      0.54      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path='./data/model2/'\n",
    "for e_name in os.listdir(path):\n",
    "    model=os.path.splitext(e_name)[0]\n",
    "    estimator=pickle.load(open(r'./data/model2/'+e_name, 'rb'))\n",
    "    pred=estimator.predict(X)\n",
    "    print('Results for ',model,':')\n",
    "    print(classification_report(y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get much better results for **certain** models, with Linear Regression having an accuracy of 76% and SVC having an accuracy of 79% as compared to our previous maximum accuracy of 65% for Gradient Boosting.<br/>\n",
    "\n",
    "The rest of our models seem to have lower test scores though this seems to be misleading as our visual test shows our models to actually perform better. The prediction accuracy may be lower overall, but predictions seem to be accurate in the important phases of the movements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
